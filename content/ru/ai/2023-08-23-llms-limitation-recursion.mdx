---
title: Большие языковые модели (LLMs) никогда не научатся решать (сложную) математику
description: Поскольку в современных архитектурах LLM отсутствует рекурсия, они в принципе не способны выполнять ряд математических операций.
date: "2023-08-23"
lastUpdated: "2024-06-24"
tags: [ml/ai]
---

_UPDATE 2024: Для ясности: этот пост о математических операциях, которые по своей природе требуют нескольких рекурсивных шагов, например возведения в степень. Как показали некоторые [крутые исследования](https://arxiv.org/abs/2405.17399v1), трансформеры при определённых доработках могут неплохо справляться с базовой арифметикой. Добавление «черновика» (scratchpad) может ещё больше улучшить работу модели и стать неплохим обходным решением проблем, упомянутых в этой статье._

## Проблема

большие языковые модели (LLMs) обладают огромным потенциалом во многих областях, но у большинства современных моделей есть одно фундаментальное ограничение: их архитектура строго однонаправленная (feed-forward). Это означает, что данные проходят линейно от входа к выходу — без рекурсии и без отката. Такой подход позволяет обучать их невероятно быстро и эффективно с использованием градиентного спуска и обратного распространения ошибки. Вычисления можно выполнять параллельно с помощью умножения матриц.

К сожалению, отсутствие рекурсии делает некоторые типы математических операций невозможными. Рассмотрим возведение в степень. ChatGPT справляется с простыми задачами на степени, но при запросах вида X^Y с большими значениями X или Y начинает ошибаться.

Хотя операции возведения в степень можно разложить на линейную последовательность, конечной однонаправленной нейросети невозможно корректно обрабатывать произвольные рекурсивные операции (то есть X^Y при любом возможном значении Y). Объём рекурсии, который большая языковая модель может «смоделировать», ограничен числом её параметров и слоёв.

## Кратко

Отсутствие рекурсии — заложенное в архитектуру нынешних больших языковых моделей (LLMs) в стиле GPT ограничение, из‑за которого они не справляются со сложными математическими операциями. Но на практике в большинстве сценариев использования больших языковых моделей это не критично! Они по‑прежнему остаются мощным и полезным инструментом во множестве ситуаций.

## Забавные штуки

Нам ещё предстоит проделать немало работы, чтобы понять поведение обученных крупных языковых моделей. Вот что любопытное я заметил, пока писал эту статью:

Когда я спросил у ChatGPT, чему равно 7^15, он выдал ответ **170,859,375**. Правильный ответ — **4,747,561,509,943**.

Хотя ответ явно неверен, у **170,859,375** есть примечательное свойство: число раскладывается как **(3^7)\*(5^7)**. Похоже, модель где-то внутри преобразовала **A^(B\*C)** в **(B^A)\*(C^A)**. Было бы интересно узнать, почему так происходит!